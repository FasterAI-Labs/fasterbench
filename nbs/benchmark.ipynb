{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "\n",
    "> Benchmark module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from typing import Sequence, Dict, Any\n",
    "from fasterbench.size     import compute_size\n",
    "from fasterbench.speed    import compute_speed_multi\n",
    "from fasterbench.compute  import compute_compute\n",
    "from fasterbench.memory   import compute_memory_multi\n",
    "from fasterbench.energy   import compute_energy_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def benchmark(\n",
    "    model: torch.nn.Module,\n",
    "    sample: torch.Tensor,\n",
    "    *,\n",
    "    metrics: Sequence[str] = (\"size\", \"speed\", \"compute\", \"memory\", \"energy\"),\n",
    "    speed_devices: Sequence[str | torch.device] | None = None,\n",
    "    memory_devices: Sequence[str | torch.device] | None = None,\n",
    "    energy_devices: Sequence[str | torch.device] | None = None,\n",
    "    **kwargs,\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    out: Dict[str, Any] = {}\n",
    "\n",
    "    if \"size\" in metrics:\n",
    "        size_metrics = compute_size(model)\n",
    "        out.update({f\"size_{k}\": v for k, v in size_metrics.as_dict().items()})\n",
    "\n",
    "    if \"speed\" in metrics:\n",
    "        speed_dict = compute_speed_multi(model, sample, devices=speed_devices, **kwargs)\n",
    "        for dev, met in speed_dict.items():\n",
    "            out.update({f\"speed_{dev}_{k}\": v for k, v in met.as_dict().items()})\n",
    "\n",
    "    if \"compute\" in metrics:\n",
    "        compute_metrics = compute_compute(model, sample)\n",
    "        out.update({f\"compute_{k}\": v for k, v in compute_metrics.as_dict().items()})\n",
    "\n",
    "    if \"memory\" in metrics:\n",
    "        mem_dict = compute_memory_multi(model, sample, devices=memory_devices, **kwargs)\n",
    "        for dev, met in mem_dict.items():\n",
    "            out.update({f\"memory_{dev}_{k}\": v for k, v in met.as_dict().items()})\n",
    "\n",
    "    if \"energy\" in metrics:\n",
    "        ene_dict = compute_energy_multi(model, sample, devices=energy_devices, **kwargs)\n",
    "        for dev, met in ene_dict.items():\n",
    "            out.update({f\"energy_{dev}_{k}\": v for k, v in met.as_dict().items()})\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
