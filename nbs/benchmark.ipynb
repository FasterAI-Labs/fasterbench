{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "\n",
    "> Benchmark module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from typing import Sequence, Dict, Any\n",
    "from fasterbench.size     import compute_size\n",
    "from fasterbench.speed    import compute_speed_multi\n",
    "from fasterbench.compute  import compute_compute\n",
    "from fasterbench.memory   import compute_memory_multi\n",
    "from fasterbench.energy   import compute_energy_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def benchmark(\n",
    "    model: torch.nn.Module,                                                      # the model to profile (can stay on CPU)\n",
    "    sample: torch.Tensor,                                                        # dummy input of the right shape\n",
    "    *,\n",
    "    metrics: Sequence[str] = (\"size\", \"speed\", \"compute\", \"memory\", \"energy\"),   # subset of {\"size\",\"speed\",\"compute\",\"memory\",\"energy\"} to compute\n",
    "    speed_devices: Sequence[str | torch.device] | None = None,                   # per-family device override; `None`means “CPU and CUDA if available”\n",
    "    memory_devices: Sequence[str | torch.device] | None = None,\n",
    "    energy_devices: Sequence[str | torch.device] | None = None,\n",
    "    **kwargs,\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    out: Dict[str, Any] = {}\n",
    "\n",
    "    if \"size\" in metrics:\n",
    "        size_metrics = compute_size(model)\n",
    "        out.update({f\"size_{k}\": v for k, v in size_metrics.as_dict().items()})\n",
    "\n",
    "    if \"speed\" in metrics:\n",
    "        speed_dict = compute_speed_multi(model, sample, devices=speed_devices, **kwargs)\n",
    "        for dev, met in speed_dict.items():\n",
    "            out.update({f\"speed_{dev}_{k}\": v for k, v in met.as_dict().items()})\n",
    "\n",
    "    if \"compute\" in metrics:\n",
    "        compute_metrics = compute_compute(model, sample)\n",
    "        out.update({f\"compute_{k}\": v for k, v in compute_metrics.as_dict().items()})\n",
    "\n",
    "    if \"memory\" in metrics:\n",
    "        mem_dict = compute_memory_multi(model, sample, devices=memory_devices, **kwargs)\n",
    "        for dev, met in mem_dict.items():\n",
    "            out.update({f\"memory_{dev}_{k}\": v for k, v in met.as_dict().items()})\n",
    "\n",
    "    if \"energy\" in metrics:\n",
    "        ene_dict = compute_energy_multi(model, sample, devices=energy_devices, **kwargs)\n",
    "        for dev, met in ene_dict.items():\n",
    "            out.update({f\"energy_{dev}_{k}\": v for k, v in met.as_dict().items()})\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/FasterAI-Labs/fasterbench/blob/main/fasterbench/benchmark.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### benchmark\n",
       "\n",
       ">      benchmark (model:torch.nn.modules.module.Module, sample:torch.Tensor,\n",
       ">                 metrics:Sequence[str]=('size', 'speed', 'compute', 'memory',\n",
       ">                 'energy'),\n",
       ">                 speed_devices:Optional[Sequence[str|torch.device]]=None,\n",
       ">                 memory_devices:Optional[Sequence[str|torch.device]]=None,\n",
       ">                 energy_devices:Optional[Sequence[str|torch.device]]=None,\n",
       ">                 **kwargs)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | the model to profile (can stay on CPU) |\n",
       "| sample | Tensor |  | dummy input of the right shape |\n",
       "| metrics | Sequence | ('size', 'speed', 'compute', 'memory', 'energy') |  |\n",
       "| speed_devices | Optional | None |  |\n",
       "| memory_devices | Optional | None |  |\n",
       "| energy_devices | Optional | None |  |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **Dict** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/FasterAI-Labs/fasterbench/blob/main/fasterbench/benchmark.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### benchmark\n",
       "\n",
       ">      benchmark (model:torch.nn.modules.module.Module, sample:torch.Tensor,\n",
       ">                 metrics:Sequence[str]=('size', 'speed', 'compute', 'memory',\n",
       ">                 'energy'),\n",
       ">                 speed_devices:Optional[Sequence[str|torch.device]]=None,\n",
       ">                 memory_devices:Optional[Sequence[str|torch.device]]=None,\n",
       ">                 energy_devices:Optional[Sequence[str|torch.device]]=None,\n",
       ">                 **kwargs)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | the model to profile (can stay on CPU) |\n",
       "| sample | Tensor |  | dummy input of the right shape |\n",
       "| metrics | Sequence | ('size', 'speed', 'compute', 'memory', 'energy') |  |\n",
       "| speed_devices | Optional | None |  |\n",
       "| memory_devices | Optional | None |  |\n",
       "| energy_devices | Optional | None |  |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **Dict** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
