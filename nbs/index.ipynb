{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasterbench\n",
    "\n",
    "> Comprehensive benchmarking toolkit for deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![PyPI version](https://badge.fury.io/py/fasterbench.svg)](https://badge.fury.io/py/fasterbench)\n",
    "[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "`fasterbench` is a powerful benchmarking library designed to help AI researchers and engineers evaluate PyTorch models across multiple dimensions:\n",
    "\n",
    "- **Size**: Model disk size and parameter count\n",
    "- **Speed**: GPU and CPU latency and throughput\n",
    "- **Compute**: MACs (multiply-accumulate operations)\n",
    "- **Memory**: GPU memory usage\n",
    "- **Energy**: Power consumption and carbon emissions\n",
    "\n",
    "Whether you're optimizing for deployment, comparing architectures, or researching model efficiency, `fasterbench` provides the metrics you need to make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install fasterbench\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from fasterbench import benchmark\n",
    "\n",
    "# Load your model\n",
    "model = resnet18()\n",
    "\n",
    "# Create sample input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Run comprehensive benchmarks\n",
    "results = benchmark(model, dummy_input)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "- **All-in-one benchmarking**: Get comprehensive metrics with a single function call\n",
    "- **GPU and CPU performance**: Compare inference speed across different hardware\n",
    "- **Environmental impact**: Measure carbon footprint with CodeCarbon integration\n",
    "- **Memory profiling**: Track peak and average GPU memory usage\n",
    "- **Model comparison**: Easily visualize differences between model variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from fasterbench import compare_models\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "\n",
    "# Define your models\n",
    "models = [resnet18(), resnet34(), resnet50()]\n",
    "\n",
    "# Compare metrics across models\n",
    "compare_models(models, dls)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "For more detailed usage examples and API documentation, visit our [documentation](https://github.com/nathanhubens/fasterbench).\n",
    "\n",
    "## Contributing\n",
    "\n",
    "Contributions are welcome! Please feel free to submit a Pull Request.\n",
    "\n",
    "## License\n",
    "\n",
    "This project is licensed under the MIT License - see the LICENSE file for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
