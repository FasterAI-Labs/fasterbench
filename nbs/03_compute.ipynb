{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute\n",
    "\n",
    "> Compute modules for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "try:\n",
    "    from thop import profile as _thop_profile\n",
    "except ImportError:\n",
    "    _thop_profile = None\n",
    "\n",
    "try:\n",
    "    from torchprofile import profile_macs as _profile_macs\n",
    "except ImportError:\n",
    "    _profile_macs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass(slots=True)\n",
    "class ComputeMetrics:\n",
    "    \"\"\"MACs (in **millions**) and parameter count (also millions).\"\"\"\n",
    "\n",
    "    macs_m: float | str  # may be \"*\" if unavailable\n",
    "    params_m: float\n",
    "\n",
    "    def as_dict(self) -> Dict[str, float | str]:\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "#| export\n",
    "def compute_compute(model: nn.Module, dummy_input: torch.Tensor) -> ComputeMetrics:\n",
    "    \"\"\"Return **ComputeMetrics** for a single forward pass.\"\"\"\n",
    "\n",
    "    params_m = round(\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6, 3\n",
    "    )\n",
    "\n",
    "    if _thop_profile is not None:\n",
    "        try:\n",
    "            mac_raw, _ = _thop_profile(model, inputs=(dummy_input,))\n",
    "            macs_m: float | str = round(mac_raw / 1e6, 3)\n",
    "        except Exception as e:  # pragma: no cover\n",
    "            warnings.warn(f\"thop failed: {e}\")\n",
    "            macs_m = \"*\"\n",
    "    elif _profile_macs is not None:\n",
    "        try:\n",
    "            macs_m = round(_profile_macs(model, dummy_input) / 1e6, 3)\n",
    "        except Exception as e:  # pragma: no cover\n",
    "            warnings.warn(f\"torchprofile failed: {e}\")\n",
    "            macs_m = \"*\"\n",
    "    else:\n",
    "        warnings.warn(\"No MAC‑counting backend available – skipping MACs\")\n",
    "        macs_m = \"*\"\n",
    "\n",
    "    return ComputeMetrics(macs_m=macs_m, params_m=params_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
